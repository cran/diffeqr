<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>

<title>GPU-Accelerated ODE Solving of Ensembles</title>

<script type="text/javascript">
window.onload = function() {
  var imgs = document.getElementsByTagName('img'), i, img;
  for (i = 0; i < imgs.length; i++) {
    img = imgs[i];
    // center an image if it is the only element of its parent
    if (img.parentElement.childElementCount === 1)
      img.parentElement.style.textAlign = 'center';
  }
};
</script>





<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 13px;
}

body {
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 20px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 {
   font-size:2.2em;
}

h2 {
   font-size:1.8em;
}

h3 {
   font-size:1.4em;
}

h4 {
   font-size:1.0em;
}

h5 {
   font-size:0.9em;
}

h6 {
   font-size:0.8em;
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre, img {
  max-width: 100%;
}
pre {
  overflow-x: auto;
}
pre code {
   display: block; padding: 0.5em;
}

code {
  font-size: 92%;
  border: 1px solid #ccc;
}

code[class] {
  background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * {
      background: transparent !important;
      color: black !important;
      filter:none !important;
      -ms-filter: none !important;
   }

   body {
      font-size:12pt;
      max-width:100%;
   }

   a, a:visited {
      text-decoration: underline;
   }

   hr {
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote {
      padding-right: 1em;
      page-break-inside: avoid;
   }

   tr, img {
      page-break-inside: avoid;
   }

   img {
      max-width: 100% !important;
   }

   @page :left {
      margin: 15mm 20mm 15mm 10mm;
   }

   @page :right {
      margin: 15mm 10mm 15mm 20mm;
   }

   p, h2, h3 {
      orphans: 3; widows: 3;
   }

   h2, h3 {
      page-break-after: avoid;
   }
}
</style>



</head>

<body>
<h2>GPU-Accelerated ODE Solving of Ensembles</h2>

<p>In many cases one is interested in solving the same ODE many times over many
different initial conditions and parameters. In diffeqr parlance this is called
an ensemble solve. diffeqr inherits the parallelism tools of the 
<a href="https://sciml.ai/">SciML ecosystem</a> that are used for things like
<a href="https://arxiv.org/abs/2001.04385">automated equation discovery and acceleration</a>.
Here we will demonstrate using these parallel tools to accelerate the solving
of an ensemble.</p>

<p>First, let&#39;s define the JIT-accelerated Lorenz equation like before:</p>

<pre><code class="R">de &lt;- diffeqr::diffeq_setup()
lorenz &lt;- function (u,p,t){
  du1 = p[1]*(u[2]-u[1])
  du2 = u[1]*(p[2]-u[3]) - u[2]
  du3 = u[1]*u[2] - p[3]*u[3]
  c(du1,du2,du3)
}
u0 &lt;- c(1.0,1.0,1.0)
tspan &lt;- c(0.0,100.0)
p &lt;- c(10.0,28.0,8/3)
prob &lt;- de$ODEProblem(lorenz,u0,tspan,p)
fastprob &lt;- diffeqr::jitoptimize_ode(de,prob)
</code></pre>

<p>Now we use the <code>EnsembleProblem</code> as defined on the 
<a href="https://diffeq.sciml.ai/stable/features/ensemble/">ensemble parallelism page of the documentation</a>:
Let&#39;s build an ensemble by utilizing uniform random numbers to randomize the
initial conditions and parameters:</p>

<pre><code class="R">prob_func &lt;- function (prob,i,rep){
  de$remake(prob,u0=runif(3)*u0,p=runif(3)*p)
}
ensembleprob = de$EnsembleProblem(fastprob, prob_func = prob_func, safetycopy=FALSE)
</code></pre>

<p>Now we solve the ensemble in serial:</p>

<pre><code class="R">sol = de$solve(ensembleprob,de$Tsit5(),de$EnsembleSerial(),trajectories=10000,saveat=0.01)
</code></pre>

<p>To add GPUs to the mix, we need to bring in <a href="https://github.com/SciML/DiffEqGPU.jl">DiffEqGPU</a>.
The <code>diffeqr::diffeqgpu_setup()</code> helper function will install CUDA for you and
bring all of the bindings into the returned object:</p>

<pre><code class="R">degpu &lt;- diffeqr::diffeqgpu_setup()
</code></pre>

<p>Now we simply use <code>EnsembleGPUArray()</code> to solve 10,000 ODEs on the GPU in parallel:</p>

<pre><code class="R">sol &lt;- de$solve(ensembleprob,de$Tsit5(),degpu$EnsembleGPUArray(),trajectories=10000,saveat=0.01)
</code></pre>

<h3>Benchmark</h3>

<p>To see how much of an effect the parallelism has, let&#39;s test this against R&#39;s
deSolve package. This is exactly the same problem as the documentation example
for deSolve, so let&#39;s copy that verbatim and then add a function to do the
ensemble generation:</p>

<pre><code class="R">library(deSolve)
Lorenz &lt;- function(t, state, parameters) {
  with(as.list(c(state, parameters)), {
    dX &lt;-  a * X + Y * Z
    dY &lt;-  b * (Y - Z)
    dZ &lt;- -X * Y + c * Y - Z
    list(c(dX, dY, dZ))
  })
}

parameters &lt;- c(a = -8/3, b = -10, c = 28)
state      &lt;- c(X = 1, Y = 1, Z = 1)
times      &lt;- seq(0, 100, by = 0.01)
out &lt;- ode(y = state, times = times, func = Lorenz, parms = parameters)

lorenz_solve &lt;- function (i){
  state      &lt;- c(X = runif(1), Y = runif(1), Z = runif(1))
  parameters &lt;- c(a = -8/3 * runif(1), b = -10 * runif(1), c = 28 * runif(1))
  out &lt;- ode(y = state, times = times, func = Lorenz, parms = parameters)
}
</code></pre>

<p>Using <code>lapply</code> to generate the ensemble we get:</p>

<pre><code>&gt; system.time({ lapply(1:1000,lorenz_solve) })
   user  system elapsed 
 225.81    0.46  226.63
</code></pre>

<p>Now let&#39;s see how the JIT-accelerated serial Julia version stacks up against that:</p>

<pre><code>&gt; system.time({ de$solve(ensembleprob,de$Tsit5(),de$EnsembleSerial(),trajectories=1000,saveat=0.01) })
   user  system elapsed 
   2.75    0.30    3.08 
</code></pre>

<p>Julia is already about 73x faster than the pure R solvers here! Now let&#39;s add
GPU-acceleration to the mix:</p>

<pre><code>&gt; system.time({ de$solve(ensembleprob,de$Tsit5(),degpu$EnsembleGPUArray(),trajectories=1000,saveat=0.01) })
   user  system elapsed 
   1.33    1.57    2.93 
</code></pre>

<p>That&#39;s only around 2x faster. But the GPU acceleartion is made for massively
parallel problems, so let&#39;s up the trajectories a bit. We will not use more
trajectories from R because that would take too much computing power, so let&#39;s
see what happens to the Julia serial and GPU at 10,000 trajectories:</p>

<pre><code>&gt; system.time({ de$solve(ensembleprob,de$Tsit5(),de$EnsembleSerial(),trajectories=10000,saveat=0.01) })
   user  system elapsed 
  35.02    4.19   39.25 
</code></pre>

<pre><code>&gt; system.time({ de$solve(ensembleprob,de$Tsit5(),degpu$EnsembleGPUArray(),trajectories=10000,saveat=0.01) })
   user  system elapsed 
  12.03    3.57   15.60
</code></pre>

<p>To compare this to the pure Julia code:</p>

<pre><code class="julia">using OrdinaryDiffEq, DiffEqGPU
function lorenz(du,u,p,t)
 @inbounds begin
     du[1] = p[1]*(u[2]-u[1])
     du[2] = u[1]*(p[2]-u[3]) - u[2]
     du[3] = u[1]*u[2] - p[3]*u[3]
 end
 nothing
end

u0 = Float32[1.0;1.0;1.0]
tspan = (0.0f0,100.0f0)
p = [10.0f0,28.0f0,8/3f0]
prob = ODEProblem(lorenz,u0,tspan,p)
prob_func = (prob,i,repeat) -&gt; remake(prob,u0=rand(Float32,3).*u0,p=rand(Float32,3).*p)
monteprob = EnsembleProblem(prob, prob_func = prob_func, safetycopy=false)
@time sol = solve(monteprob,Tsit5(),EnsembleGPUArray(),trajectories=10_000,saveat=0.01f0)

# 9.444439 seconds (22.96 M allocations: 6.464 GiB, 44.53% gc time)
</code></pre>

<p>which is more than an order of magnitude faster for computing 10,000 trajectories,
note that the major factors are that we cannot define 32-bit floating point values
from R and the <code>prob_func</code> for generating the initial conditions and parameters
is a major bottleneck since this function is written in R.</p>

<p>To see how this scales in Julia, let&#39;s take it to insane heights. First, let&#39;s
reduce the amount we&#39;re saving:</p>

<pre><code class="julia">@time sol = solve(monteprob,Tsit5(),EnsembleGPUArray(),trajectories=10_000,saveat=1.0f0)
# 0.801215 seconds (1.66 M allocations: 133.846 MiB)
</code></pre>

<p>This highlights that controlling memory pressure is key with GPU usage: you will
get much better performance when requiring less saved points on the GPU.</p>

<pre><code class="julia">@time sol = solve(monteprob,Tsit5(),EnsembleGPUArray(),trajectories=100_000,saveat=1.0f0)
# 1.871536 seconds (6.66 M allocations: 919.521 MiB, 2.48% gc time)
</code></pre>

<p>compared to serial:</p>

<pre><code class="julia">@time sol = solve(monteprob,Tsit5(),EnsembleSerial(),trajectories=100_000,saveat=1.0f0)
# 22.136743 seconds (16.40 M allocations: 1.628 GiB, 42.98% gc time)
</code></pre>

<p>And now we start to see that scaling power! Let&#39;s solve 1 million trajectories:</p>

<pre><code class="julia">@time sol = solve(monteprob,Tsit5(),EnsembleGPUArray(),trajectories=1_000_000,saveat=1.0f0)
# 25.234710 seconds (56.53 M allocations: 8.579 GiB, 51.61% gc time)
</code></pre>

<p>For reference, let&#39;s look at deSolve with the change to only save that much:</p>

<pre><code class="R">times      &lt;- seq(0, 100, by = 1.0)
lorenz_solve &lt;- function (i){
  state      &lt;- c(X = runif(1), Y = runif(1), Z = runif(1))
  parameters &lt;- c(a = -8/3 * runif(1), b = -10 * runif(1), c = 28 * runif(1))
  out &lt;- ode(y = state, times = times, func = Lorenz, parms = parameters)
}

system.time({ lapply(1:1000,lorenz_solve) })
</code></pre>

<p>The GPU version is solving 1000x as many trajectories, 2x as fast! So conclusion,
if you need the most speed, you may want to move to the Julia version to get the
most out of your GPU due to Float32&#39;s, and when using GPUs make sure it&#39;s a problem
with a relatively average or low memory pressure, and these methods will give
orders of magnitude acceleration compared to what you might be used to.</p>

</body>

</html>
